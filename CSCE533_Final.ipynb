{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPd24Yn+4DzwfNupMDnzFH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjdunand/NodeClassification/blob/main/CSCE533_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's make sure all dependencies are properly installed. This is a bit of a weird way to do it, but I was having a problem with \"Building the wheel\" for torch-sparse. The fix was from this StackOverflow discussion:\n",
        "https://stackoverflow.com/questions/67285115/building-wheels-for-torch-sparse-in-colab-takes-forever"
      ],
      "metadata": {
        "id": "sW7lB5m6svQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ],
      "metadata": {
        "id": "_c7ImORdTJS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's set a seed for both the CPU and GPU to ensure reproducibility.\n",
        "The following code was from ChatGPT 11/23/2024 using the prompt:\n",
        "\"What is the best way to set a random seed for PyTorch to ensure reproducability?\"\n"
      ],
      "metadata": {
        "id": "4pqKxp5iyySd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "Etlkkpx4zAOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first use a somewhat \"default\" GCN model. No specific hyperparemeter tuning or data transformations will be used. The accuracy and AUC results from this run (on the CORA dataset) will be used as a baseline to compare possible improvements to both later on."
      ],
      "metadata": {
        "id": "YigfIa1KsiaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoenMrL9TBJB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# load cora using pytorch geometric\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "\n",
        "\n",
        "# create graph conv model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        # starting with 2 layers\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data): # standard forward pass. unsure if relu needed after second conv (assuming log_softmax works in it's place for nonlinearity)\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# send to gpu if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) # \"default\"-ish parameters\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) # mask on trainable samples (still somewhat weird to me)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# for validation\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask]: # use the \"validation\" masks this time\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# keep a held-aside set of data for a final evaluation\n",
        "def final_test():\n",
        "    model.eval()\n",
        "    logits = model(data)\n",
        "    test_mask = data.test_mask\n",
        "\n",
        "    preds = logits[test_mask].max(1)[1].cpu().numpy()\n",
        "    probs = F.softmax(logits[test_mask], dim=1).cpu().detach().numpy() # logits -> probabilities\n",
        "    true_labels = data.y[test_mask].cpu().numpy()\n",
        "\n",
        "    accuracy = (preds == true_labels).sum() / test_mask.sum().item()\n",
        "\n",
        "    # compute AUC\n",
        "    auc = roc_auc_score(\n",
        "        F.one_hot(torch.tensor(true_labels), dataset.num_classes).numpy(),\n",
        "        probs,\n",
        "        multi_class=\"ovr\",\n",
        "    )\n",
        "\n",
        "    return accuracy, auc\n",
        "\n",
        "\n",
        "# training loop\n",
        "best_val_acc = 0\n",
        "for epoch in range(200):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        train_acc, val_acc = test()\n",
        "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
        "              f'Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # cool feature of loading a previously \"best\" performing model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "# use best model on the final test set\n",
        "model.load_state_dict(best_model_state)\n",
        "test_acc, test_auc = final_test()\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}, Test AUC: {test_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next, let's try implementing k-fold cross validation, as the CORA dataset is somewhat small (at least compared to traditional deep learning benchmark datasets)\n",
        "\n",
        "We will mainly do this because it seems our baseline model overfit the data a bit (the training accuracy hit 100% very quickly)\n",
        "\n",
        "We will split the dataset into an 80/20 for train(and val) and testing sets, respectively.\n",
        "\n",
        "Using 5-fold cross validation, we will see which model performs the best on the validation sets, and use that model for the final, unbiased accuracy and auc test on unseen data."
      ],
      "metadata": {
        "id": "P-LH0V7QqpXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import torch\n",
        "\n",
        "def kFoldTrain(numFolds, modelType, num_epochs):\n",
        "\n",
        "  # use sklearn to split the data easily\n",
        "  data = dataset[0]\n",
        "  data.to(device)\n",
        "  num_nodes = data.num_nodes\n",
        "  train_val_idx, test_idx = train_test_split(range(num_nodes), test_size=0.2, random_state=42)\n",
        "\n",
        "  # keep a held aside testing set that remains unseen until the very end\n",
        "  data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "  data.test_mask[test_idx] = True\n",
        "\n",
        "  # use sklearn again for k-fold cross validation\n",
        "  kf = KFold(n_splits=numFolds, shuffle=True, random_state=42)\n",
        "  fold_accuracies = []\n",
        "  fold_aucs = []\n",
        "\n",
        "  # main loop\n",
        "  for fold_idx, (train_idx, val_idx) in enumerate(kf.split(train_val_idx)):\n",
        "      print(f\"Fold {fold_idx + 1}/{numFolds}\")\n",
        "\n",
        "     # get train and val data for this fold\n",
        "      train_fold_idx = [train_val_idx[i] for i in train_idx]\n",
        "      val_fold_idx = [train_val_idx[i] for i in val_idx]\n",
        "\n",
        "      # just to be able to use different models (later)\n",
        "      if (modelType == \"BaseGCN\"):\n",
        "        model = GCN().to(device)\n",
        "      elif (modelType == \"DeeperGCN\"):\n",
        "        model = DeeperGCN().to(device)\n",
        "      else:\n",
        "        print(\"Invalid model type\")\n",
        "        return\n",
        "\n",
        "      # same optimizer and hyperparameters\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "      # set up masks\n",
        "      data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "      data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "      data.train_mask[train_fold_idx] = True\n",
        "      data.val_mask[val_fold_idx] = True\n",
        "\n",
        "      # train!\n",
        "      best_val_acc = 0\n",
        "      for epoch in range(num_epochs):\n",
        "          model.train()\n",
        "          optimizer.zero_grad()\n",
        "          out = model(data)\n",
        "          loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) # negative log likelihood. good for multiclass classifier\n",
        "          loss.backward() # compute gradients\n",
        "          optimizer.step() # update parameters\n",
        "\n",
        "          # validation\n",
        "          if epoch % 10 == 0:\n",
        "              model.eval()\n",
        "              logits = model(data)\n",
        "              train_pred = logits[data.train_mask].max(1)[1]\n",
        "              val_pred = logits[data.val_mask].max(1)[1]\n",
        "              train_acc = train_pred.eq(data.y[data.train_mask]).sum().item() / data.train_mask.sum().item()\n",
        "              val_acc = val_pred.eq(data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
        "              print(f'Epoch {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "\n",
        "              if val_acc > best_val_acc:\n",
        "                  best_val_acc = val_acc\n",
        "                  best_model_state = model.state_dict()\n",
        "\n",
        "      model.load_state_dict(best_model_state)\n",
        "      model.eval()\n",
        "      logits = model(data)\n",
        "      val_pred = logits[data.val_mask].max(1)[1]\n",
        "      val_acc = val_pred.eq(data.y[data.val_mask]).sum().item() / data.val_mask.sum().item()\n",
        "\n",
        "      # AUC\n",
        "      probs = F.softmax(logits[data.val_mask], dim=1).cpu().detach().numpy()\n",
        "      true_labels = data.y[data.val_mask].cpu().numpy()\n",
        "      auc = roc_auc_score(\n",
        "          F.one_hot(torch.tensor(true_labels), dataset.num_classes).numpy(),\n",
        "          probs,\n",
        "          multi_class=\"ovr\",\n",
        "      )\n",
        "\n",
        "      print(f\"Fold {fold_idx + 1} Val Accuracy: {val_acc:.4f}, Val AUC: {auc:.4f}\")\n",
        "      fold_accuracies.append(val_acc)\n",
        "      fold_aucs.append(auc)\n",
        "\n",
        "  # performance metrics\n",
        "  avg_accuracy = sum(fold_accuracies) / numFolds\n",
        "  avg_auc = sum(fold_aucs) / numFolds\n",
        "  print(f\"\\nK-Fold Cross-Validation Results:\")\n",
        "  print(f\"Average Validation Accuracy: {avg_accuracy:.4f}, Average Validation AUC: {avg_auc:.4f}\")\n",
        "\n",
        "  # final evaluation on held-aside data\n",
        "  model.load_state_dict(best_model_state)  # Use the best model found across folds\n",
        "  model.eval()\n",
        "  logits = model(data)\n",
        "  test_mask = data.test_mask\n",
        "\n",
        "  # final accuracy\n",
        "  test_pred = logits[test_mask].max(1)[1]\n",
        "  test_acc = test_pred.eq(data.y[test_mask]).sum().item() / test_mask.sum().item()\n",
        "\n",
        "  # final auc\n",
        "  test_probs = F.softmax(logits[test_mask], dim=1).cpu().detach().numpy()\n",
        "  test_labels = data.y[test_mask].cpu().numpy()\n",
        "  test_auc = roc_auc_score(\n",
        "      F.one_hot(torch.tensor(test_labels), dataset.num_classes).numpy(),\n",
        "      test_probs,\n",
        "      multi_class=\"ovr\",\n",
        "  )\n",
        "\n",
        "  print(f\"Hold-out Test Accuracy: {test_acc:.4f}, Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "\n",
        "# able to change model or num epochs\n",
        "kFoldTrain(5, \"BaseGCN\", 200)"
      ],
      "metadata": {
        "id": "LjV3w-idqw8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've seen some significant improvements on the accuracy using k-fold cross validation, let's see if normalization on the data can help using a PyTorch transformation!"
      ],
      "metadata": {
        "id": "0UQscuJ3x0_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create graph conv model\n",
        "class DeeperGCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeeperGCN, self).__init__()\n",
        "        # 2 gcnconv layers\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
        "        self.conv2 = GCNConv(32, 16)\n",
        "\n",
        "        # try some fully connected layers!\n",
        "        self.fc1 = torch.nn.Linear(16, 32)\n",
        "        self.fc2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data): # standard forward pass. unsure if relu needed after second conv (assuming log_softmax works in it's place for nonlinearity)\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        # fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "kFoldTrain(5, \"DeeperGCN\", 200)"
      ],
      "metadata": {
        "id": "naWp2KCW2Gga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try one final experiment: increase the training time from 200 epochs to 1,000!"
      ],
      "metadata": {
        "id": "BnOWbHes4ZD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kFoldTrain(5, \"DeeperGCN\", 1000)"
      ],
      "metadata": {
        "id": "sQldrV2d4UYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we will run similar experiments using the Citeseer dataset!\n",
        "\n",
        "First, we will use the baseline training algorithm with our \"default\" GCN model"
      ],
      "metadata": {
        "id": "40VGkbnVXVrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "dataset = Planetoid(root='/tmp/Citeseer', name='Citeseer')\n",
        "\n",
        "# create graph conv model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        # starting with 2 layers\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data): # standard forward pass. unsure if relu needed after second conv (assuming log_softmax works in it's place for nonlinearity)\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# send to gpu if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) # \"default\"-ish parameters\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) # mask on trainable samples (still somewhat weird to me)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# for evaluating on unseen data\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask]: # use the \"validation\" masks this time\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# keep a held-aside set of data for a final evaluation\n",
        "def final_test():\n",
        "    model.eval()\n",
        "    logits = model(data)\n",
        "    test_mask = data.test_mask\n",
        "\n",
        "    preds = logits[test_mask].max(1)[1].cpu().numpy()\n",
        "    probs = F.softmax(logits[test_mask], dim=1).cpu().detach().numpy() # logits -> probabilities\n",
        "    true_labels = data.y[test_mask].cpu().numpy()\n",
        "\n",
        "    accuracy = (preds == true_labels).sum() / test_mask.sum().item()\n",
        "\n",
        "    # compute AUC\n",
        "    auc = roc_auc_score(\n",
        "        F.one_hot(torch.tensor(true_labels), dataset.num_classes).numpy(),\n",
        "        probs,\n",
        "        multi_class=\"ovr\",\n",
        "    )\n",
        "\n",
        "    return accuracy, auc\n",
        "\n",
        "\n",
        "# training loop\n",
        "best_val_acc = 0\n",
        "for epoch in range(200):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        train_acc, val_acc = test()\n",
        "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
        "              f'Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # cool feature of loading a previously \"best\" performing model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "# use best model on the final test set\n",
        "model.load_state_dict(best_model_state)\n",
        "test_acc, test_auc = final_test()\n",
        "print(f\"Final Test Accuracy: {test_acc:.4f}, Test AUC: {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "hcaV_CjYXYZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like we're having the same issue of overfitting the training data like we did with Cora (only, it's worse now!). Let's try to see what K-Fold cross validation can do for us."
      ],
      "metadata": {
        "id": "ceonbMJXXxqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kFoldTrain(5, \"BaseGCN\", 200)"
      ],
      "metadata": {
        "id": "EmYdQwqgXwtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much better accuracy from employing 5-fold cross validation. Next, let's see if increasing the model depth can help us get the representation power we need to model the more challenging Citeseer dataset."
      ],
      "metadata": {
        "id": "fdWW5KmqX_gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kFoldTrain(5, \"DeeperGCN\", 200)"
      ],
      "metadata": {
        "id": "DrwCME0vYJDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh no! It actually decreased the performance to have more layers! Maybe we should try playing with number of epochs to give the model a chance to learn even more parameters from the fully-connected layers."
      ],
      "metadata": {
        "id": "cufN1we1YOxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kFoldTrain(5, \"DeeperGCN\", 1000)"
      ],
      "metadata": {
        "id": "ET01q3Wq2AHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}